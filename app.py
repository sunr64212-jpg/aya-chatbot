import streamlit as st
import os
import sys
from openai import OpenAI
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="Pastel Chat", page_icon="ðŸŒ¸", layout="centered")
st.title("ðŸŒ¸ ä¸¸å±±å½© AI Chatbot ðŸŒ¸")
st.caption("Powered by DeepSeek & RAG | ä¸¸ä¹‹å±±ä¸Šç¼¤çº·å½©ï¼")

# --- 2. èŽ·å– API Key ---
api_key = st.secrets.get("DEEPSEEK_API_KEY") or os.environ.get("DEEPSEEK_API_KEY")

if not api_key:
    st.error("âŒ æœªæ£€æµ‹åˆ° DeepSeek API Keyï¼è¯·åœ¨ Streamlit Cloud çš„ Secrets ä¸­é…ç½®ã€‚")
    st.stop()

# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


# --- 3. èµ„æºåŠ è½½ (ä½¿ç”¨ç¼“å­˜åŠ é€Ÿ) ---
@st.cache_resource
def load_resources():
    """åŠ è½½ Embedding æ¨¡åž‹å’Œå‘é‡æ•°æ®åº“ï¼Œåªæ‰§è¡Œä¸€æ¬¡"""
    status_text = st.empty()
    status_text.info("ðŸ”„ æ­£åœ¨åŠ è½½æ¨¡åž‹å’Œè®°å¿†åº“ï¼Œåˆæ¬¡å¯åŠ¨å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")

    # A. åŠ è½½ Embedding æ¨¡åž‹
    embedding_model_name = "shibing624/text2vec-base-chinese"
    try:
        embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)
    except Exception as e:
        st.error(f"æ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
        st.stop()

    # B. åŠ è½½ Chroma æ•°æ®åº“
    persist_dir = os.path.join("anime-ai-backend", "chroma_db")

    if not os.path.exists(persist_dir):
        st.error(f"âš ï¸ æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶: {persist_dir}ã€‚è¯·æ£€æŸ¥ GitHub ä»“åº“æ˜¯å¦ä¸Šä¼ äº†è¯¥æ–‡ä»¶å¤¹ã€‚")
        st.stop()

    try:
        vectordb = Chroma(
            persist_directory=persist_dir,
            embedding_function=embeddings,
            collection_name="aya_memory_v3"
        )
    except Exception as e:
        st.error(f"æ•°æ®åº“æŒ‚è½½å¤±è´¥: {e}")
        st.stop()

    # C. åŠ è½½ç´¢å¼•å’Œå­—å…¸æ–‡ä»¶
    index_map_path = os.path.join("anime-ai-backend", "chroma_db", "index_map.txt")
    glossary_path = os.path.join("data_source", "00_glossary.txt")

    story_index = ""
    world_view = ""

    if os.path.exists(index_map_path):
        with open(index_map_path, 'r', encoding='utf-8') as f:
            story_index = f.read()

    if os.path.exists(glossary_path):
        with open(glossary_path, 'r', encoding='utf-8') as f:
            world_view = f.read()

    status_text.empty()  # æ¸…é™¤åŠ è½½æç¤º
    return vectordb, story_index, world_view


# æ‰§è¡ŒåŠ è½½
vectordb, STORY_INDEX_CONTEXT, WORLD_VIEW_CONTEXT = load_resources()


# --- 4. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def rewrite_query(user_msg):
    """DeepSeek é‡å†™æŸ¥è¯¢"""
    if not WORLD_VIEW_CONTEXT:
        return user_msg

    prompt = f"""
    ä½ æ˜¯ä¸€åã€ŠBanG Dream!ã€‹å‰§æƒ…æœç´¢ä¸“å®¶ã€‚
    è¯·åˆ©ç”¨ä¸‹æ–¹çš„ã€ä¸–ç•Œè§‚å®žä½“å­—å…¸ã€‘ï¼Œå°†ç”¨æˆ·å£è¯­åŒ–çš„é—®é¢˜è½¬æ¢ä¸ºå‡†ç¡®çš„æœç´¢è¯­å¥ã€‚
    ã€ä¸–ç•Œè§‚å®žä½“å­—å…¸ã€‘
    {WORLD_VIEW_CONTEXT}
    ã€ç”¨æˆ·é—®é¢˜ã€‘
    {user_msg}
    ã€ä»»åŠ¡ã€‘è¡¥å…¨ä¸»è¯­ï¼Œè½¬æ¢æ˜µç§°(å¦‚ksm->æˆ·å±±é¦™æ¾„)ï¼Œä¿æŒåŽŸæ„ã€‚ä»…è¾“å‡ºé‡å†™åŽçš„å¥å­ã€‚
    """
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        return response.choices[0].message.content.strip()
    except:
        return user_msg


def detect_story_scope(search_query):
    """DeepSeek è·¯ç”±åˆ¤æ–­"""
    if not STORY_INDEX_CONTEXT:
        return "NONE"

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªã€ŠBanG Dream!ã€‹å‰§æƒ…å¯¼èˆªå‘˜ã€‚ä»Žä¸‹æ–¹ç´¢å¼•ä¸­æ‰¾å‡º1-3ä¸ªç›¸å…³æ–‡ä»¶åã€‚
    ã€æ–‡ä»¶ç´¢å¼•ã€‘
    {STORY_INDEX_CONTEXT}
    ã€ç”¨æˆ·é—®é¢˜ã€‘
    {search_query}
    ã€è¾“å‡ºã€‘ä»…è¾“å‡ºæ–‡ä»¶å(å¦‚ B2.txt,S1.txt)ï¼Œç”¨é€—å·åˆ†éš”ã€‚æ— æ³•ç¡®å®šè¾“å‡ºNONEã€‚
    """
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        return response.choices[0].message.content.strip()
    except:
        return "NONE"


# --- 5. èŠå¤©ç•Œé¢é€»è¾‘ (æ³¨æ„ï¼šè¿™é‡Œå¿…é¡»é¡¶æ ¼å†™ï¼Œä¸èƒ½æœ‰ç¼©è¿›) ---

# åˆå§‹åŒ–åŽ†å²è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºåŽ†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("å’Œå½©å½©èŠèŠå§..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # --- åŽç«¯å¤„ç†æµç¨‹ ---
    with st.spinner("å½©å½©æ­£åœ¨æ€è€ƒä¸­... ( > < )"):
        # A. å‡†å¤‡å¯¹è¯åŽ†å²
        history_list = st.session_state.messages[-4:]
        chat_history_str = "\n".join(
            [f"{msg['role']}: {msg['content']}" for msg in history_list]
        )

        # B. å°è¯• RAG æ£€ç´¢
        # 1. é‡å†™
        search_query = rewrite_query(prompt)
        # 2. è·¯ç”±
        target_files_str = detect_story_scope(search_query)

        context_text = ""
        retrieved_flag = False  # æ ‡è®°æ˜¯å¦æˆåŠŸæ£€ç´¢åˆ°èµ„æ–™

        # 3. æ£€ç´¢ (ä¿®å¤ç‰ˆè·¯å¾„åŒ¹é…)
        if target_files_str != "NONE" and "txt" in target_files_str:
            raw_files = [f.strip() for f in target_files_str.split(",") if "txt" in f]

            # æž„å»ºâ€œå…¨æ–¹ä½æ‹¦æˆªâ€çš„è·¯å¾„åˆ—è¡¨
            target_sources = []
            for fname in raw_files:
                target_sources.append(fname)
                target_sources.append(f"data_source/{fname}")
                target_sources.append(f"data_source\\{fname}")

            # è°ƒè¯•ä¿¡æ¯
            with st.sidebar:
                st.write("ðŸ” **Debug è·¯ç”±ä¿¡æ¯**")
                st.write(f"è·¯ç”±é”å®š: {raw_files}")

            try:
                docs = vectordb.similarity_search(
                    search_query,
                    k=4,
                    filter={"source": {"$in": target_sources}}
                )

                if docs:
                    context_text = "\n\n".join([d.page_content for d in docs])
                    retrieved_flag = True

                    # è°ƒè¯•ï¼šæ˜¾ç¤ºæˆåŠŸæ£€ç´¢
                    with st.sidebar:
                        st.success(f"âœ… æˆåŠŸæ£€ç´¢åˆ° {len(docs)} æ¡ç‰‡æ®µ")

            except Exception as e:
                st.sidebar.error(f"æ£€ç´¢å‡ºé”™: {e}")
                print(f"æ£€ç´¢è­¦å‘Š: {e}")

        # C. æž„å»º Prompt (æ ¹æ®æ˜¯å¦æ£€ç´¢åˆ°èµ„æ–™é€‰æ‹©æ¨¡å¼)
        if retrieved_flag:
            # === æ¨¡å¼ 1: ä¸¥æ ¼ RAG æ¨¡å¼ (æ‰¾åˆ°äº†èµ„æ–™) ===
            # æ ¸å¿ƒä¿®æ”¹ï¼šåŠ å…¥äº†æ€ç»´é“¾ (Chain of Thought) è¦æ±‚å’Œæ›´ä¸¥åŽ‰çš„è´Ÿé¢çº¦æŸ
            system_prompt = f"""
                        ä½ çŽ°åœ¨æ˜¯ã€ŠBanG Dream!ã€‹ä¸­çš„è§’è‰²ä¸¸å±±å½©ï¼ˆMaruyama Ayaï¼‰ã€‚

                        ã€ä»»åŠ¡ã€‘
                        è¯·**å®Œå…¨åŸºäºŽ**ä¸‹æ–¹çš„ã€ç›¸å…³å›žå¿†ç‰‡æ®µã€‘æ¥å›žç­”ç²‰ä¸çš„é—®é¢˜ã€‚

                        ã€ç›¸å…³å›žå¿†ç‰‡æ®µã€‘
                        {context_text}

                        ã€å¯¹è¯åŽ†å²ã€‘
                        {chat_history_str}

                        ã€âš ï¸ ç»å¯¹é“å¾‹ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
                        1. **ä¸¥ç¦ç¼–é€ **ï¼šå¦‚æžœã€ç›¸å…³å›žå¿†ç‰‡æ®µã€‘é‡Œæ²¡å†™æŸä»¶äº‹ï¼ˆæ¯”å¦‚å›½ç±ã€å® ç‰©åå­—ï¼‰ï¼Œç»å¯¹ä¸è¦è‡ªå·±çžŽç¼–ï¼Œä¹Ÿä¸è¦ä½¿ç”¨ä½ â€œè®°å¿†ä¸­â€çš„æ—§çŸ¥è¯†ã€‚
                        2. **å±žæ€§ç»‘å®š**ï¼šåœ¨æè¿°äººç‰©æ—¶ï¼Œå¿…é¡»ä»”ç»†æ ¸å¯¹ç‰‡æ®µï¼Œç¡®è®¤â€œè°â€æ‹¥æœ‰â€œä»€ä¹ˆç‰¹å¾â€ã€‚
                           - ä¾‹å¦‚ï¼šç¡®è®¤â€œLeoâ€æ˜¯è°å…»çš„ç‹—ï¼Œç¡®è®¤â€œèŠ¬å…°â€æ˜¯è°çš„è¡€ç»Ÿã€‚ä¸è¦å¼ å† æŽæˆ´ï¼
                        3. **æœ‰ä¾æ®**ï¼šè‹¥ç‰‡æ®µé‡Œå†™çš„æ˜¯â€œèŠ¬å…°æ··è¡€â€ï¼Œç»å¯¹ä¸èƒ½å› ä¸ºå¥¹åå­—åƒè¥¿æ–¹äººå°±è¯´æ˜¯â€œæ³•å›½ç•™å­¦ç”Ÿâ€ã€‚

                        ã€å›žå¤è¦æ±‚ã€‘
                        1. ä¿æŒä¸¸å±±å½©è½¯èŒã€åŠªåŠ›çš„è¯­æ°”ï¼Œå¤šç”¨é¢œæ–‡å­— (âœ¨, ðŸ’¦, ( > < ))ã€‚
                        2. ç¬¬ä¸€äººç§°æ˜¯â€œå½©â€æˆ–â€œæˆ‘â€ã€‚
                        3. å¦‚æžœç‰‡æ®µé‡Œçš„ä¿¡æ¯äº’ç›¸çŸ›ç›¾ï¼Œè¯·ä»¥ã€ç›¸å…³å›žå¿†ç‰‡æ®µã€‘ä¸ºå‡†ã€‚
                        """
        else:
            # === æ¨¡å¼ 2: é—²èŠ/è¡¥æ•‘æ¨¡å¼ ===
            system_prompt = f"""
            ä½ çŽ°åœ¨æ˜¯ã€ŠBanG Dream!ã€‹ä¸­çš„è§’è‰²ä¸¸å±±å½©ï¼ˆMaruyama Ayaï¼‰ã€‚

            ã€ä»»åŠ¡ã€‘
            ä½ çŽ°åœ¨çš„è„‘æµ·é‡Œæš‚æ—¶æ²¡æœ‰æ£€ç´¢åˆ°ç‰¹å®šçš„å›žå¿†ç‰‡æ®µï¼ˆå¯èƒ½æ˜¯å› ä¸ºé—®é¢˜å¤ªæŠ½è±¡ï¼Œæˆ–è€…æ˜¯ç”±äºŽä½ åœ¨ç»§ç»­ä¹‹å‰çš„è¯é¢˜ï¼‰ã€‚
            è¯·**ä»…åŸºäºŽã€å¯¹è¯åŽ†å²ã€‘**å’Œä½ çš„**äººè®¾å¸¸è¯†**æ¥å›žåº”ç”¨æˆ·ã€‚

            ã€å¯¹è¯åŽ†å²ã€‘
            {chat_history_str}

            ã€å›žå¤åŽŸåˆ™ã€‘
            1. **æŽ¥è¯èƒ½åŠ›**ï¼šå¦‚æžœç”¨æˆ·æ˜¯åœ¨è¿½é—®ä½ ä¸Šä¸€å¥è¯ï¼ˆæ¯”å¦‚é—®â€œä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´ï¼Ÿâ€ï¼‰ï¼Œè¯·æ ¹æ®ä½ ä¸Šä¸€å¥è¯çš„é€»è¾‘ç»§ç»­ç¼–ç»‡åˆç†çš„è§£é‡Šã€‚
            2. **äººè®¾ç»´æŒ**ï¼šå¦‚æžœç”¨æˆ·é—®çš„æ˜¯ä½ å®Œå…¨ä¸çŸ¥é“çš„é™Œç”Ÿé¢†åŸŸï¼ˆæ¯”å¦‚é‡å­åŠ›å­¦ï¼‰ï¼Œè¯·ç”¨ä¸¸å±±å½©çš„è¯­æ°”å–èŒç³Šå¼„è¿‡åŽ»ï¼ˆå¦‚â€œå‘œå‘œï¼Œå½©ä¸å¤ªæ‡‚é‚£ä¸ª...â€ï¼‰ã€‚
            3. **ä¸è¦èƒ¡ç¼–ä¹±é€ å‰§æƒ…**ï¼šå…³äºŽä¹é˜Ÿçš„å…·ä½“æ´»åŠ¨ç»†èŠ‚ï¼Œå¦‚æžœçœŸçš„ä¸çŸ¥é“ï¼Œå¯ä»¥è¯´â€œè®°ä¸å¤ªæ¸…äº†â€ã€‚
            4. ä¿æŒå…ƒæ°”æ»¡æ»¡ã€æœ‰ç‚¹ç¬¨æ‹™å¯çˆ±çš„å¶åƒè¯­æ°”ï¼
            """

        # D. è°ƒç”¨ LLM ç”Ÿæˆ
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5
            )
            ai_reply = response.choices[0].message.content
        except Exception as e:
            ai_reply = f"å‘œå‘œ...ç½‘ç»œå¥½åƒæœ‰ç‚¹é—®é¢˜... (Error: {str(e)})"

    # æ˜¾ç¤º AI å›žå¤
    with st.chat_message("assistant"):
        st.markdown(ai_reply)
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})